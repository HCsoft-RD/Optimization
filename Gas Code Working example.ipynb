{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container{width:70%;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container{width:70%;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from IPython.core.display import clear_output\n",
    "from shaolin.core.dashboard import Dashboard #pip install shaolin should make it work\n",
    "from test_functions import TestFunctions\n",
    "import copy\n",
    "\n",
    "#from collections import deque\n",
    "\n",
    "\n",
    "class TabuList(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self,pos=None,val=None,memory_size=100):\n",
    "        \"\"\"Class that manages the algorithm memory. The memory consists of the previous visited local minima.\n",
    "            These local minima will act as a repeling force that forces the walkers to visit unexplored areas\n",
    "        \"\"\"\n",
    "        \n",
    "        self._Nd = len(pos)\n",
    "        self.N = memory_size\n",
    "        self.positions = np.tile(pos,(self.N,1))\n",
    "        self.values = np.ones(self.N).reshape(self.N,1)*np.nan#nan for not used\n",
    "        self.values[:2] = val\n",
    "        self._pos_cand =[] if pos is None else [pos]\n",
    "        self._val_cand = [] if val is None else [val]\n",
    "        self.flows = np.zeros(self.N).reshape(self.N,1)\n",
    "        \n",
    "    \n",
    "    def reset_cands(self):\n",
    "        \"\"\"This list acts like a buffer. When updating the content of the tabu list,\n",
    "        the best point in the candidates list will be added to the tabu list\"\"\"\n",
    "        self._pos_cand = [] \n",
    "        self._val_cand = []\n",
    "\n",
    "    @property\n",
    "    def alives(self):\n",
    "        cond = np.logical_not(np.isnan(self.values))\n",
    "        res = np.arange(len(cond))[cond.flatten()]\n",
    "        alives = res.reshape(len(res),1)\n",
    "        return alives.flatten()\n",
    "    \n",
    "    @property\n",
    "    def max_cand(self):\n",
    "        \"\"\"Returns the position with the best associated value from the candidates list\"\"\"\n",
    "        ix = self._val_cand.index(max(self._val_cand))\n",
    "        return self._pos_cand[ix],self._val_cand[ix]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the tabu list\"\"\"\n",
    "        return len(self.values)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"Prints the pairs (position,value) of the tabu list\"\"\"\n",
    "        s = \"\"\n",
    "        for i,pos in enumerate(self.positions):\n",
    "            s += str(pos)+\" : \"+str(self.values[i])+\"\\n\"\n",
    "        return s\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Returns the position i in the tabu list\"\"\"\n",
    "        return self.positions[i]\n",
    "    \n",
    "    def random_alive(self):\n",
    "        \"\"\"Returns the index that correspond to valid memories\"\"\"\n",
    "        ix = np.random.choice(np.arange(len(self.alives)))\n",
    "        return self.values[ix].flatten()\n",
    "    \n",
    "    def flow(self):\n",
    "        \"\"\"Flow metric analogous to the one used in the fractal taking into account the values of the tabu list \n",
    "            instead of the algorithm walkers. That means that the tabu list will act as some sort of \"memory walkers\"\n",
    "\n",
    "        \"\"\"\n",
    "        min_pot = self.values[self.alives.flatten()].min()\n",
    "        max_pot = self.values[self.alives.flatten()].max()\n",
    "        #Calculate a normalized version of the potential of the positions contained in the tabu list\n",
    "        unstarted_val = (np.ones(len(self.values[self.alives]))*-1).reshape(len(self.values[self.alives]),1)\n",
    "        norm_val = ((self.values[self.alives]-min_pot)/(max_pot-min_pot))*0.9+0.1 \n",
    "        \n",
    "        self.scaled_pot = unstarted_val if max_pot==min_pot else norm_val\n",
    "        self.scaled_pot = self.scaled_pot.reshape(len(self.alives),1)\n",
    "        #Distance from a randomly chosen compaion. In this case the random companion is sampled as a permutation\n",
    "        #of the original values, meaning that all the values in the list will be chosen for comparison\n",
    "        companions = self.compas()\n",
    "        res = self.positions-self.positions[companions]        \n",
    "        self.distance = np.linalg.norm(res,axis=1).reshape(self.N,1)        \n",
    "        self.flows[self.alives.flatten()] = self.distance[self.alives.flatten()]*(self.scaled_pot+1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def compas(self):\n",
    "        \"\"\"returns a random companion index for clone purposes\"\"\"\n",
    "        return np.random.permutation(np.arange(self.N)).astype(int)\n",
    "    \n",
    "    def clone(self):\n",
    "        \"\"\"Decide if pairs of randomly chosen tabu list elements should be cloned\"\"\"\n",
    "        #Random companions like in the flow function\n",
    "        companions = self.compas()\n",
    "        #probability of clone depends on the flow ratio between the two selected companions\n",
    "        probs = np.minimum(1,np.maximum(0,(self.flows[companions]-self.flows)/np.maximum(1e-8,self.flows)))\n",
    "        #will clone with probability p\n",
    "        will_clone = np.random.random(size=len(self.values))<probs.flatten()\n",
    "        #dont clone to unstarted memories\n",
    "        for i,c in enumerate(companions):\n",
    "            if np.isnan(self.values[c]):\n",
    "                will_clone[i]=False\n",
    "        #clone the selected values\n",
    "        cloned = copy.copy(self.positions)\n",
    "        values = copy.copy(self.values)\n",
    "        for i,x in enumerate(will_clone.tolist()):\n",
    "            if x:\n",
    "                cloned[i,:] = self.positions[companions[i],:]\n",
    "                values[i] = self.values[companions[i]]\n",
    "        self.positions = cloned\n",
    "        self.values = values\n",
    "        \n",
    "    \n",
    "    def update_list(self):\n",
    "        \"\"\"Updates the tabu list elements with the best element from the candidates buffer.\n",
    "            This update process will not only add one more element to the tabu list, but also will\n",
    "            clone some values of the tabu list to a randomly chosen companion depending on its flow \n",
    "            ratio.\n",
    "        \"\"\"\n",
    "        pos,val = self.max_cand\n",
    "        self._append_tabu(pos,val)\n",
    "        self.flow()\n",
    "        self.clone()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def append(self,pos,val):\n",
    "        \"\"\"Adds a new pair of (position,value) to the candidates list\"\"\"\n",
    "        self._pos_cand.append(pos)\n",
    "        self._val_cand.append(val)\n",
    "       \n",
    "    \n",
    "    def _append_tabu(self,pos,val):\n",
    "        \"\"\"Updates the content of the tabu list with the selected (pos,val).\n",
    "           This upodate will depend on the selected density value\n",
    "        \"\"\"\n",
    "        if len(self.alives)==self.N:\n",
    "            ix = np.random.randint(len(self.values))\n",
    "        else:\n",
    "            deads = np.arange(self.N)[np.isnan(self.values.flatten())]\n",
    "            ix = np.random.choice(deads)\n",
    "        \n",
    "        self.positions[ix,:] = pos\n",
    "        self.values[ix] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Walkers(Dashboard):\n",
    "    \"\"\"Class in charge of iterating walkers\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pot_func,\n",
    "                 alpha=1,\n",
    "                 minjump=None,\n",
    "                 max_temp=1,\n",
    "                 mean_temp=-0.1,\n",
    "                 min_temp=-1.,\n",
    "                 tabu_len=10,\n",
    "                 \n",
    "                 num_walkers=150,\n",
    "                 **kwargs\n",
    "                ):\n",
    "        def _end_callback():\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        self.end_callback = _end_callback\n",
    "        self.pot_func = pot_func\n",
    "        \n",
    "        \n",
    "        dash = [\"r$N=Fractal_opt\",[[\"c$N=temp_col\",[\"(-10.,10.,0.1,\"+str(float(mean_temp))+\")$d=Mean temp\",\n",
    "                                                    \"(-10.,10.,0.1,\"+str(float(min_temp))+\")$d=min temp\",\n",
    "                                                    \"(-10.,10.,0.1,\"+str(float(max_temp))+\")$d=Max temp\"]\n",
    "                                   ],[\"c$N=gaussian_col\",[\"(1,10000,1,\"+str(num_walkers)+\")$d=Num walkers\",\n",
    "                                                          [\"r$n=samp_opts\",[\"True$d=Sample mean\",\"False$d=Fractal LJ\"]]\n",
    "                                                         ]\n",
    "                                   ],[\"c$N=generic_col\",[\n",
    "                                                      \"(1,10000,1,\"+str(tabu_len)+\")$d=Tabu len\",\n",
    "                                                       ]\n",
    "                                     ]\n",
    "                                  ]\n",
    "               ]\n",
    "        Dashboard.__init__(self,dash,**kwargs) \n",
    "        self.reset()\n",
    "   \n",
    "\n",
    "\n",
    "    @property\n",
    "    def best_so_far(self):\n",
    "        return -self._best_so_far\n",
    "    @best_so_far.setter\n",
    "    def best_so_far(self,val):\n",
    "        self._best_so_far = val\n",
    "        \n",
    "    @property\n",
    "    def best_pos_so_far(self):\n",
    "        return self.pot_func.unscale(self._best_pos_so_far)\n",
    "    @best_pos_so_far.setter\n",
    "    def best_pos_so_far(self,val):\n",
    "        self._best_pos_so_far =val\n",
    "    \n",
    "   \n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Initializes the parameters of the algorithm\"\"\"\n",
    "        #these are scaled\n",
    "        positions = np.array([self.pot_func.to_scaled(self.pot_func.random_in_domain()) for _ in range(self.num_walkers.value)])\n",
    "        self.positions = positions.reshape(self.num_walkers.value,len(self.pot_func.random_in_domain()))\n",
    "        #init tracking of best solution\n",
    "        self._best_so_far = -1e100\n",
    "        self._best_pos_so_far = np.ones(len(self.positions[0]))*1000\n",
    "        self.tabu_list = TabuList(self._best_pos_so_far,self._best_so_far)\n",
    "        #init internal parameters\n",
    "        self.jumps = np.ones(self.num_walkers.value)\n",
    "        self.potentials = np.zeros(self.num_walkers.value)\n",
    "        self.calculate_potential()\n",
    "        if self.fractal_lj.value:\n",
    "            self.best_pos = self.positions[0,:]\n",
    "            self.max_pot = -1*self.pot_func.evaluate(self.pot_func.unscale(self.positions))[0]\n",
    "        self._best_pos_so_far = self.best_pos\n",
    "        self._best_so_far = self.max_pot\n",
    "        #same jump scale forever\n",
    "        minscale = self.mean_temp.value+self.min_temp.value\n",
    "        maxscale = self.mean_temp.value+self.max_temp.value\n",
    "        self.minjump = 10.0**minscale\n",
    "        self.maxjump = 10.0**maxscale     \n",
    "        #finish initialization\n",
    "        self.calculate_jumps()\n",
    "        self.tabu_list = TabuList(self._best_pos_so_far,self._best_so_far,memory_size=self.tabu_len.value)\n",
    "        self.update_best()\n",
    "        \n",
    "       \n",
    "       \n",
    "    def _TTF(self,i):\n",
    "        \"\"\"Tabu list score for one walker\"\"\"\n",
    "        a = self.positions[i,:]\n",
    "        b = self.tabu_list.random_alive()\n",
    "        c = np.linalg.norm(a-b)**2\n",
    "        return 1+np.log(1+c)\n",
    "    \n",
    "    def tabu_tunneling(self):\n",
    "        \"\"\"Calculate the tabu list scores for all the walkers\"\"\"\n",
    "        ttf = []\n",
    "        for i in range(len(self.potentials)):\n",
    "            ttf.append(self._TTF(i))\n",
    "        return np.array(ttf).reshape(len(self.potentials),1)\n",
    "        \n",
    "        \n",
    "    def calculate_potential(self):\n",
    "        \"Calculates function and tabu potentials for all the walkers\"\n",
    "        def fractal_lennard(U,N):\n",
    "            U = U.reshape(N,3)\n",
    "            npart = len(U)\n",
    "            Epot = 0.0\n",
    "            particles = np.random.choice(np.arange(npart),size=1,replace=False)\n",
    "            for i in particles:\n",
    "                samples = np.arange(npart)\n",
    "                samples = samples[samples!=i]\n",
    "                compas = np.random.choice(samples,size=2,replace=False)\n",
    "                r1 = np.linalg.norm(U[compas[0],:]-U[i,:])**2\n",
    "                p1_6 = r1*r1*r1\n",
    "                p1_12 = p1_6*p1_6\n",
    "                r2 = np.linalg.norm(U[compas[1],:]-U[i,:])**2\n",
    "                p2_6 = r2*r2*r2\n",
    "                Epot = p1_12-p2_6\n",
    "            return Epot\n",
    "\n",
    "        if self.fractal_lj.value:\n",
    "            try:\n",
    "                potential = -1*np.array([fractal_lennard(self.pot_func.unscale(self.positions)[i,:],self.pot_func.N) for i in range(self.positions.shape[0])])\n",
    "                potential = potential.reshape(self.positions.shape[0],1)\n",
    "            except:\n",
    "                print(\"fallo random\")#fails when using custom lennard jonnes\n",
    "                raise\n",
    "        else:\n",
    "            #internally a maximization\n",
    "            potential = -1*self.pot_func.evaluate(self.pot_func.unscale(self.positions))\n",
    "        self.tabu_pot = self.tabu_tunneling()\n",
    "        self.best_i = np.argmax(potential)\n",
    "        min_pot = min(potential)\n",
    "        max_pot = max(potential)\n",
    "        #keep track of best\n",
    "        if not self.fractal_lj.value:\n",
    "            self.max_pot = max(self._best_so_far,max_pot)\n",
    "            self.best_pos = self.positions[self.best_i,:] if self.max_pot != self._best_so_far else self._best_pos_so_far\n",
    "        else:\n",
    "            self.max_pot = max_pot\n",
    "            self.best_pos = self.positions[self.best_i,:]\n",
    "        #potentials scaled from 0.1 to 1\n",
    "        new_pots = (((potential-min_pot)/(max_pot-min_pot))*0.9+0.1 if max_pot!=min_pot else np.ones(len(potential))*0.99).reshape(len(potential),1)\n",
    "        self.potentials = new_pots\n",
    "       \n",
    "\n",
    "        \n",
    "    def calculate_jumps(self):\n",
    "        \"\"\"Calculates the jump value for the random walk process\"\"\"\n",
    "        self.jumps = self.minjump+(self.maxjump-self.minjump)*(1-self.potentials)\n",
    "        self.jumps = self.jumps.reshape(len(self.jumps),1)\n",
    "    \n",
    "    \n",
    "    def _local_search(self,pos):\n",
    "        \"\"\"Appends to the tabu list the result of a local search on pos and keeps track of it.\"\"\"\n",
    "        self.tabu_list.reset_cands()\n",
    "        result = minimize(self.pot_func.evaluate,\n",
    "                                  self.pot_func.unscale(pos),\n",
    "                                  bounds=self.pot_func.domain,\n",
    "                                  method=\"L-BFGS-B\",\n",
    "                                 )\n",
    "        loc_pos = self.pot_func.to_scaled(result.x)\n",
    "        loc_val = -result.fun\n",
    "        self.tabu_list.append(loc_pos,loc_val)\n",
    "        self.tabu_list.update_list()\n",
    "        max_pos,max_val = self.tabu_list.max_cand  \n",
    "        improves = max_val>self._best_so_far\n",
    "        in_dom = self.pot_func.in_domain(self.pot_func.unscale(max_pos))\n",
    "        if improves and in_dom:\n",
    "            dif = np.linalg.norm(self._best_pos_so_far-max_pos)\n",
    "            self._best_pos_so_far = max_pos\n",
    "            self._best_so_far = max_val\n",
    "        \n",
    "    \n",
    "    def update_best(self):\n",
    "        \"\"\"Ads to the tabu list a local optimization of the best walker on this epoch\"\"\"\n",
    "        self._local_search(self.best_pos)\n",
    "        if self.sample_mean.value:\n",
    "            mean = (self.positions*self.potentials/self.potentials.sum()).sum(axis=0)\n",
    "            self._local_search(mean)\n",
    "  \n",
    "       \n",
    "        \n",
    "    def gaussian_step(self):\n",
    "        \"\"\"Random perturbations of the positions of the walkers\"\"\"\n",
    "        old_pos = self.positions.copy()\n",
    "        pos_s = old_pos.shape\n",
    "       \n",
    "        dof = 2*np.random.random(size=pos_s)-1\n",
    "        norm = dof/np.linalg.norm(dof)\n",
    "        \n",
    "        vel_mod = np.abs(np.array([np.random.normal(loc=0,scale=self.jumps[i]) for i in range(min(len(self.jumps),pos_s[0]))])).reshape(min(len(self.jumps),pos_s[0]),1)\n",
    "        new_pos = old_pos+vel_mod*norm\n",
    "        #If new position not in function domain, take a new step with half of the initial jump\n",
    "        #until all the new position are in the function domain.\n",
    "        for i in range(pos_s[0]):\n",
    "            num_try=0\n",
    "            while not self.pot_func.in_domain(self.pot_func.unscale(new_pos[i,:])) and num_try<100:\n",
    "                dof = 2*np.random.random(size=pos_s[1])-1\n",
    "                norm_i = dof/np.linalg.norm(dof)\n",
    "                new_vel = np.abs(np.random.normal(loc=0,scale=self.jumps[i]/(2**num_try+1)))\n",
    "                new_pos[i,:] = old_pos[i,:]+new_vel*norm_i\n",
    "                vel_mod[i,:] = new_vel\n",
    "                num_try +=1\n",
    "                if num_try==100:\n",
    "                    print(new_pos[i,:],new_vel)\n",
    "                    raise\n",
    "        self.vel  = vel_mod\n",
    "        self.positions = new_pos\n",
    "        self._old_pos = old_pos\n",
    "        \n",
    "        \n",
    "    def step(self):\n",
    "        \"Perform one iteration of the algorithm\"\n",
    "        self.calculate_potential()\n",
    "        self.calculate_jumps()\n",
    "        self.update_best()\n",
    "        self.gaussian_step()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FractalOptimizer(Dashboard):\n",
    "    def __init__(self,\n",
    "                 pot_func,\n",
    "                 max_temp=1,\n",
    "                 mean_temp=-0.2,\n",
    "                 min_temp=-1.,\n",
    "                 num_walkers=100,\n",
    "                 max_epoch=100000,\n",
    "                 tabu_len=100,\n",
    "                 max_reads=50000,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        walkers = Walkers(pot_func,\n",
    "                          num_walkers=num_walkers,\n",
    "                          name='walkers',\n",
    "                          mean_temp=mean_temp,\n",
    "                          min_temp=min_temp,\n",
    "                          max_temp=max_temp,\n",
    "                          tabu_len=tabu_len)\n",
    "        dash = [\"r$N=fractal_opt\",[ \"##Fractal$n=title\",\n",
    "                                   [\"r$N=fractal_opt_controls\",[\n",
    "                                       [\"c$N=fractal_col\",[\"(0,1000000,1,\"+str(max_epoch)+\")$d=Max epoch\",\n",
    "                                                       \"(0,10000000,1,\"+str(max_reads)+\")$d=Max reads\",\n",
    "                                                       \"btn$d=Run&n=run_btn\"\n",
    "                                                        ]\n",
    "                                       ],walkers]\n",
    "                                  ]\n",
    "               ]]\n",
    "        Dashboard.__init__(self,dash,**kwargs)\n",
    "        self.run_btn.observe(self.run)\n",
    "\n",
    "    #Aliases and general properties of the fractal algorithm   \n",
    "    @property\n",
    "    def num_walkers(self):\n",
    "        return self.walkers.num_walkers\n",
    "    @property\n",
    "    def pot_func(self):\n",
    "        return self.walkers.pot_func\n",
    "    @pot_func.setter\n",
    "    def pot_func(self,val):\n",
    "        self.walkers.pot_func = val\n",
    "    \n",
    "    @property\n",
    "    def positions(self):\n",
    "        return self.walkers.positions\n",
    "    @positions.setter\n",
    "    def positions(self,val):\n",
    "        self.walkers.positions =val\n",
    "    \n",
    "    @property\n",
    "    def potentials(self):\n",
    "        return self.walkers.potentials\n",
    "    @property\n",
    "    def best_so_far(self):\n",
    "        return self.walkers.best_so_far\n",
    "    @property\n",
    "    def best_pos_so_far(self):\n",
    "        return self.walkers.best_pos_so_far\n",
    "    @property\n",
    "    def n_reads(self):\n",
    "        return self.walkers.pot_func.n_reads\n",
    "    \n",
    "    @n_reads.setter\n",
    "    def n_reads(self,val):\n",
    "        self.walkers.pot_func.n_reads = val\n",
    "        \n",
    "    @property\n",
    "    def step(self):\n",
    "        return self.walkers.step\n",
    "    \n",
    "    @property\n",
    "    def best(self):\n",
    "        return (self.walkers.best_pos_so_far,self.walkers.best_so_far)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Resets the optimization process to its initial parameters\"\"\"\n",
    "        self.epoch = 0\n",
    "        self.n_reads = 0\n",
    "        self.walkers.reset()\n",
    "    \n",
    "    def random_alives(self):\n",
    "        \"\"\"Return a list o length num_walkers containing the\n",
    "        index of a diferent random walker in the function domain.\n",
    "        \"\"\"\n",
    "        self.alive_ix = np.arange(self.walkers.num_walkers.value).tolist()\n",
    "        #sampling with replacement of random alive companions\n",
    "        alives = np.random.choice(self.alive_ix,size=(self.walkers.num_walkers.value))\n",
    "        #ensure a walker doesnt compare to itself\n",
    "        companions = [x+1 if alives[i]==i and i!=len(alives)-1 else x for i,x in enumerate(alives)]\n",
    "        #if its comparing to itself pick the next one\n",
    "        companions[-1] = companions[-1] if alives[-1]!=len(alives)-1 else companions[-2]\n",
    "        return companions\n",
    "        \n",
    "        \n",
    "    def flow(self):\n",
    "        \"calculate the flow metric of all the walkers\"\n",
    "        companions = self.random_alives()\n",
    "        self.distance = np.linalg.norm(self.positions-self.positions[companions],axis=1).reshape(self.num_walkers.value,1)\n",
    "        self.flows = self.distance*(self.potentials+1)*self.walkers.tabu_pot\n",
    "        \n",
    "    \n",
    "    def clone(self):\n",
    "        \"\"\"Clone different walkers with a probability depending on the flow\"\"\"\n",
    "        companions = self.random_alives()\n",
    "        #comparing flows as (compa-walker)/walker bounded from 0 to 1\n",
    "        probs = np.minimum(1,np.maximum(0,(self.flows[companions]-self.flows)/np.maximum(1e-8,self.flows)))\n",
    "        #evaluate probabilities\n",
    "        \n",
    "        will_clone = np.random.random(size=self.num_walkers.value)<probs.flatten()\n",
    "        #clone selected walkers\n",
    "        cloned = copy.copy(self.positions)\n",
    "        for i,x in enumerate(will_clone.tolist()):\n",
    "            if x:\n",
    "                cloned[i,:] = self.positions[companions[i],:]\n",
    "        self.positions = cloned\n",
    "        return cloned\n",
    "    \n",
    "    def run(self,_=None, end_callback=None):\n",
    "        \"\"\"Run the algorithm the selected number of iteration or until a custom callback condition is met\"\"\"\n",
    "        #callback config\n",
    "        def _end_callback():\n",
    "            return False\n",
    "        if end_callback is None:\n",
    "            end_callback = _end_callback\n",
    "        self.walkers.end_callback = end_callback\n",
    "        #main loop\n",
    "        self.reset()\n",
    "        time_start = time.time()\n",
    "        while not end_callback() and self.epoch<self.max_epoch.value and self.n_reads < self.max_reads.value:   \n",
    "            self.step()\n",
    "            self.flow()\n",
    "            self.clone()\n",
    "            self.epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funcs = TestFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = FractalOptimizer(funcs.functions['eggholder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e700329b03e24f409f7fa8f097efb15c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalidus/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:109: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "optimizer[0]#click run to perform optimization, ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 512.        ,  404.23180496]), -959.64066272085086)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.best# return X, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
